---
output: github_document

references:
- id: schweinberger2015
  title: "Local Dependence in Random Graph Models: Characterization, Properties and Statistical Inference"
  author:
  - family: Schweinberger
    given: Michael
  - family: Handcock
    given: Mark S
  container-title: Journal of the Royal Statistical Society B
  volume: 77
  issue: 3
  page: 647-676
  type: article-journal
  issued:
    year: 2015

- id: vu_2013
  title: "Model-based clustering of large networks"
  author:
  - family: Vu
    given: Duy
  - family: Hunter
    given: Davind
  - family: Schweinberger
    given: Michael
  container-title: The Annals of Applied Statistics
  volume: 7
  issue: 2
  page: 1010-1039
  type: article-journal
  issued:
    year: 2013
    
- id: babkin_2020
  title: "Large-scale estimation of random graph models with local dependence"
  author:
  - family: Babkin
    given: Sergii
  - family: Stewart
    given: Jonathan
  - family: Schweinberger
    given: Michael
  container-title: Computational Statistics & Data Analysis
  volume: 152
  page: 107029
  type: article-journal
  issued:
    year: 2020

- id: schweinberger2018
  title: "hergm: Hierarchical Exponential-Family Random Graph Models"
  author:
  - family: Schweinberger
    given: Michael
  - family: Luna
    given: Pamela
  container-title: Journal of Statistical Software
  volume: 85
  issue: 1
  page: 1-39
  type: article-journal
  issued:
    year: 2018

- id: fritz2024
  title: "A strategic model of software dependency networks"
  author:
  - family: Fritz
    given: Cornelius
  - family: Georg
    given: Co-Piere
  - family: Mele
    given: Angelo
  - family: Schweinberger
    given: Michael
  type: article-journal
  page: Working Paper. Available at https://arxiv.org/abs/2402.13375
  issued:
    year: 2024
    
- id: martinezdahbura2021
  title: "A Structural Model of Business Card Exchange Networks"
  author:
  - family: MartÃ­nez Dahbura
    given: Juan Nelson
  - family: Komatsu
    given: Shota
  - family: Nishida
    given: Takanori
  - family: Mele
    given: Angelo
  type: article-journal
  page: Working Paper. Available at https://arxiv.org/abs/2105.12704
  issued:
    year: 2021
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```


# `bigergm`: Estimating Exponential-Family Random Graph Models for Large Networks

This vignette provides a brief introduction on how to use the R package `bigergm`, which estimates Hierarchical Exponential-Family Random Graph Models [HERGMs, @schweinberger2015].
`bigergm` is built upon the R packages `lighthergm`[@martinezdahbura2021] and `hergm` [@schweinberger2018] and applies scalable algorithms and computational techniques.
See @martinezdahbura2021  and @fritz2024 for further information on the implementation enhancements for undirected and directed networks, respectively. In this vignette, we will focus on undirected networks.

Exponential Random Graph Models (ERGMs) are a popular class of models for network data. 
They model the probability of observing a network as a function of network statistics, such as the number of edges and triangles. ERGMs are commonly employed in social network analysis but have some limitations when applied to large networks. The main limitation is that the likelihood function is intractable for large networks, making it difficult to estimate the model parameters. 
At the same time, larger networks warrant more complex models to capture the underlying structure of the network.

To address these limitations, `bigergm` implements a scalable algorithm for estimating HERGMs, which generalize ERGMs that allow for local dependence induced by non-overlapping blocks of nodes with network data. 
Introduced by @schweinberger2015, dependence is allowed only between nodes within the same block. 
This allows for a more flexible model that can capture the cohesive subgroups in the network globally while accounting for dependence within these subgroups on the local level.


# Installation

You can install the github version of `bigergm` by running the following command:
```{r, eval=FALSE}
devtools::install_github("corneliusfritz/bigergm-tutorial"). 
```


# A simple example

Let's start with a simple example using the toy network included in the package.
The toy network is a small network with a clear community structure, which is useful for testing the package.

```{r setup, results=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
library(bigergm)
library(ergm)
library(dplyr)

```



```{r, message=FALSE}
# Load an embedded network object.
data(toyNet)
# Draw the network.
plot(toyNet, vertex.col = rep(c("tomato", "steelblue", "darkgreen", "black"),
                        each = toyNet$gal$n/4))
```

It is clearly visible that this network has a cluster or community structure.
Although this is an artificial network, we often observe such community structures in real social networks.
Exploiting this stylized fact, we model the way population members in a network get connected differently for connections across and within communities:

- Connections across communities happen by luck, influenced by homophily
- Connections within communities also consider interdependencies among links.
For example, the probability that agent $i$ and $j$ gets connected may be influenced by a friend in common $k$.

We can estimate the model using the `bigergm::bigergm()` function, which estimates the model in two steps: first, it recovers the latent community structure, and then it estimates the model parameters.
The parameter "object" specifies a formula for the model to estimate (this is the same as in `ergm::ergm()`).
If the parameter "clustering_with_features" is set to TRUE, the algorithm takes into account nodematch on characteristics when clustering.
Also, the effects for the between block networks are assumed to be all terms from the provided formula that do not induce any dependence. The effects for the within block networks are assumed to be all terms from the provided formula.
The parameter "n_clusters" specifies the number of blocks to recover.
The parameter "n_MM_step_max" specifies the maximum number of MM algorithm steps.
The parameter "tol_MM_step" details when convergence is reached.
In particular, the algorithm stops when the relative change in the lower bound of the objective function is less than "tol_MM_step".
The parameter "estimate_parameters" specifies whether to estimate the parameters after the block recovery step.
The parameter "check_block_membership" specifies whether to keep track of block memberships at each EM iteration.
There are other parameters that you can specify, which are detailed in the documentation (see `help(bigergm)`).


```{r, message=FALSE}
model_formula <- toyNet ~ edges + nodematch("x") + nodematch("y") + triangle

bigergm_res <-bigergm(
    # The model you would like to estimate
    object = model_formula,
    # The number of blocks
    n_blocks = 4,
    # The maximum number of MM algorithm steps
    n_MM_step_max = 100,
    # The tolerance for the MM algorithm
    tol_MM_step = 1e-6,
    # Perform parameter estimation after the block recovery step
    estimate_parameters = TRUE,
    # Indicate that clustering must take into account nodematch on characteristics
    clustering_with_features = TRUE,
    # Keep track of block memberships at each EM iteration
    check_block_membership = TRUE
)
```

To see whether the first step (recovering the latent community structure) has converged, we can plot the estimated lower bound of the objective function over iterations.

```{r}
plot(1:length(bigergm_res$MM_lower_bound),
     bigergm_res$MM_lower_bound, type = "l", xlab = "Iterations", ylab = "Lower Bound")
```

This indicates that the clustering step converged at the early stage.
Note that the number of iterations that you need to perform (`n_MM_step_max`) varies depending on the size of a network, whether it has a clear community structure, etc..
You need trial and error on how many iterations are at least necessary in your case.
Plotting the lower bound may help check the convergence of the clustering step.

You can check the clustering result by plotting the network with nodes colored by the estimated block membership.
The colour of the edges is grey if the two population members are from different blocks and black otherwise. 

```{r}
plot(bigergm_res)
```

and estimated parameters.

```{r}
# For the between networks
summary(bigergm_res$est_between)
```

```{r}
# For the within networks
summary(bigergm_res$est_within)
```

Currently, the only supported way to include covariates in the model is via `nodematch()`.

You can also employ caching to avoid repeating heavy operations that yield the same results for your network. To use it, pass the `cache` parameter to `bigergm::bigergm`, setting its value to a [cachem](https://github.com/r-lib/cachem "cachem repository") object. A disk cache lets you speed up estimations on the same network data even across R Sessions.

# Simulation

You can simulate networks with local dependence using the function `bigergm::simulate_bigergm()`.
The function requires the estimated coefficients for the between and within connections, the formula for the model, the data frame containing the nodes attributes, the name of the column containing the node IDs, the name of the column containing the block IDs, the MCMC settings, the number of simulations to return, and the output format.
Depending on the output format, the function returns a list with the network statistics for the between and within connections, the adjacency matrix of the simulated network, or the network object itself.

```{r, message=FALSE, echo=TRUE}
# Estimated coefficients for the between-community connections
coef_between_block <- coef(bigergm_res$est_between)

# Estimated coefficients for the within-community connections
coef_within_block <- coef(bigergm_res$est_within)


# The MCMC settings
sim_ergm_control <- ergm::control.simulate.formula(
  MCMC.burnin = 1000000,
  MCMC.interval = 100000
)
sim_net <- bigergm::simulate_bigergm(
  formula = model_formula,
  # The coefficients for the between connections
  coef_between = coef_between_block,
   # The coefficients for the within connections
  coef_within = coef_within_block,
  # The MCMC settings
  control_within = sim_ergm_control,
  # Number of simulations to return
  n_sim = 1,
  # If `stats` a list with network statistics 
  # for the between and within connections is returned
  output = "network"
)
```

After simulating the network, you can plot it to check whether the community structure is preserved.

```{r}
plot(sim_net)
```

# Goodness-of-fit

Following the estimation, you may want to evaluate the goodness-of-fit of the model.
In line with the ERGM literature, we provide a goodness-of-fit test that evaluates the model's fit to the observed network.
In the \code{bigergm} package, we provide a function \code{gof()} to carry out this task:

```{r, message=FALSE}
gof_res <- gof(
  # The object returned by bigergm::bigergm()
  object = bigergm_res,
  # The MCMC settings
  control_within = sim_ergm_control,
  # The number of simulations to use
  n_sim = 100, 
  # Compute the geodesic distance for the observed and each simulated network
  compute_geodesic_distance = TRUE,
  # Start at the observed network
  start_from_observed = TRUE
)

```

The procedure evaluates the following metrics:

1. network statistics (the counts you obtain when you use summary on an ergm formula, such as the number of edges, triangles, nodematches, etc.),

2. normalized network statistics (the network statistics normalized around the observed statistics),

3. degree distribution, 

4. geodesic distance, and

5. edgewise shared partners.

`bigergm::gof_bigergm()` returns a list of data frames for these matrices instead of creating plots as `ergm::gof()` does.
This allows you to flexibly create plots that match your needs.
Below is a example plot for the degree distribution on the log scale.

```{r, message=FALSE, warning=FALSE}
degree_gof <- 
  gof_res$simulated$degree_dist %>%
  dplyr::group_by(degree) %>%
  dplyr::summarise(log_mean_share = mean(log(share)),
                   log_sd_share = sd(log(share))) %>%
  dplyr::ungroup()
plot(degree_gof$degree, degree_gof$log_mean_share,
     xlab = "Degree", ylab = "Log Prop. of Nodes",
     ylim = c(-5.5,-1.8), xlim = c(6,20), type = "l", lty = 2)
lines(degree_gof$degree, degree_gof$log_mean_share+ 1.96 * degree_gof$log_sd_share, type = "l", lty = 2)
lines(degree_gof$degree, degree_gof$log_mean_share- 1.96 * degree_gof$log_sd_share, type = "l", lty = 2)
tmp_info <- gof_res$original$degree_dist %>% 
  dplyr::filter(share > 0 & degree < 22)
lines(tmp_info$degree, log(tmp_info$share), lty = 1)
```

Alternatively, you can use the `plot()` function to visualize the goodness-of-fit results.
Three plots are generated checking whether the estimated model can adequately capture the degree distribution, edgewise-shared partner distribution, geodesic distances of the observed network. 
In the fourth plot the simulated network statistics normalized around the observed statistics are ploted. 
For a good fit, all values should be around zero.
In all plots, the red line represents the observed network, and the boxplot represents the simulated networks.

```{r}
plot(gof_res)
```


# When you work with large networks

If you would like to estimate an bigergm with a large network (say, when the number of nodes $\geq$ 50,000):

- Select features sparse enough to fit into memory. Covariates such as gender or race will be too dense to construct feature matrices. This is a non-negligible limitation of our algorithm and will be solved in the future. 
- Prepare a list of multiplied feature adjacency matrices by `bigergm::compute_multiplied_feature_matrices()`, and pass it to `bigergm::bigergm()` by `list_multiplied_feature_matrices`. Once calculated and stored, it can be used in models with the same network and the same features.
- Use Python's infomap to initialize clusters. This is because it is much faster to implement cluster initialization than R functions such as `igraph::cluster_infomap()`. To install it, run `system("pip3 install infomap")` and check if it is effective by `system("infomap --version")`. If `system("infomap --version")` yields an error, consider using `{reticulate}`.
- If successfully installed Python's infomap, set `use_infomap_python = TRUE` in `bigergm::bigergm()`.
- When the MM estimation does not seem to have converged by inspecting the lower bound plot, you can further continue iterating by passing the `bigergm` class object to `bigergm::bigergm()` as follows (all parameters such as the number of MM iterations will be inherited from the previous estimation unless specified).

```{r, message=FALSE}
bigergm_res_second <-
  bigergm::bigergm(object = bigergm_res)
```


# References
